{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOSOivcAIStk8d9wdQ6TC4o"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikexcohen/Calculus_book/blob/main/exercises/ch18_statistics_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculus unraveled: Intuition, Proofs, and Python**\n",
        "### Mike X Cohen (sincxpress.com)\n",
        "#### https://github.com/mikexcohen/calculus_book\n",
        "#### Code for Chapter 18 (Integration applications in statistics)\n",
        "\n",
        "---\n",
        "\n",
        "# About this code file:\n",
        "\n",
        "### This notebook contains full code solutions to the exercises in this book chapter. There are many correct ways to solve the exercises; this notebook provides *a* solution, not *THE* solution. Please use this code as a starting point to continue exploring and experimenting with calculus concepts and visualizations.\n",
        "\n",
        "## **Using the code without the book may lead to confusion or errors.**\n",
        "\n",
        "#### This code was written in google-colab. The notebook may require some modifications if you use a different IDE."
      ],
      "metadata": {
        "id": "4KikZVyDDDXR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2nu8jtVmMzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYWhHwGQ9OdD"
      },
      "outputs": [],
      "source": [
        "# import libraries and define global settings\n",
        "import numpy as np\n",
        "import sympy as sym\n",
        "import scipy.integrate as spi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# new in this chapter\n",
        "import sympy.stats\n",
        "import scipy.stats as stats\n",
        "\n",
        "# define global figure properties used for publication\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg') # display figures in vector format\n",
        "plt.rcParams.update({'font.size':14,             # font size\n",
        "                     'savefig.dpi':300,          # output resolution\n",
        "                     'axes.titlelocation':'left',# title location\n",
        "                     'axes.spines.right':False,  # remove axis bounding box\n",
        "                     'axes.spines.top':False,    # remove axis bounding box\n",
        "                     'lines.linewidth':2         # increase default line thickness\n",
        "                     })"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HEWzoPonrC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 18.1: cdfs from pdfs"
      ],
      "metadata": {
        "id": "aomuA544nq_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xx = np.linspace(-4,4,9001)\n",
        "dx = xx[1]-xx[0]\n",
        "sigma = 1\n",
        "\n",
        "# pdf\n",
        "pdf = 1/np.sqrt(2*np.pi*sigma**2) * np.exp( -xx**2/(2*sigma**2) )\n",
        "\n",
        "# cdf via numpy\n",
        "cdf_np = np.cumsum(pdf*dx)\n",
        "\n",
        "# cdf via scipy.integrate\n",
        "cdf_sp = spi.cumulative_simpson(pdf,dx=dx,initial=0)\n",
        "\n",
        "# cdf via scipy.stats\n",
        "cdf_st = stats.norm.cdf(xx)\n",
        "\n",
        "# compare\n",
        "_,axs = plt.subplots(1,2,figsize=(12,4))\n",
        "axs[0].plot(xx,pdf*dx,'k')\n",
        "axs[0].set(xlim=xx[[0,-1]],xlabel='$x$',ylabel='Probability density',title=r'$\\bf{A}$)  pdf')\n",
        "\n",
        "axs[1].plot(xx,cdf_np,'k',label='np.cumsum')\n",
        "axs[1].plot(xx[::200],cdf_sp[::200],'o',color=[.5,.5,.5],markerfacecolor=[.9,.9,.9],label='spi.cumulative_')\n",
        "axs[1].plot(xx[::200],cdf_st[::200],'x',color=[.5,.5,.5],markersize=8,label='stats.norm')\n",
        "axs[1].set(xlim=xx[[0,-1]],xlabel='$x$',ylabel='Cumulative probability',title=r'$\\bf{B}$)  cdfs')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('stats_ex1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "riMwDWT5nuaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sv93tcdZnq5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 18.2: non-analytic distribution"
      ],
      "metadata": {
        "id": "nKDsgNVMnq2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2000\n",
        "# individual datasets\n",
        "data1 = stats.logistic.rvs(size=N//2)\n",
        "data2 = stats.wald.rvs(2,size=N//2)\n",
        "\n",
        "# combined dataset\n",
        "data = np.zeros(N)\n",
        "data[::2] = data1\n",
        "data[1::2] = data2\n",
        "\n",
        "\n",
        "# visualize\n",
        "_,axs = plt.subplots(1,3,figsize=(14,4))\n",
        "\n",
        "axs[0].plot(data,'ko',alpha=.3)\n",
        "axs[0].set(xlabel='Data index',ylabel='Data value',title=r'$\\bf{A}$)  Simulated data')\n",
        "\n",
        "\n",
        "colors = [ [.5,.5,.5],[.7,.7,.7],'k']\n",
        "markers = [ 'o','^',None ]\n",
        "\n",
        "for idx,D in enumerate((data1,data2,data)):\n",
        "\n",
        "  # extract the histogram (empirical distribution)\n",
        "  heights,bins = np.histogram(D,bins='auto')\n",
        "  binCenters = (bins[:-1]+bins[1:]) / 2\n",
        "\n",
        "  # estimate the pdf/cdf\n",
        "  pdfEst = heights / N\n",
        "  cdfEst = np.cumsum(pdfEst)\n",
        "\n",
        "  axs[1].plot(binCenters,pdfEst,color=colors[idx],marker=markers[idx],markerfacecolor='w')\n",
        "  axs[1].set(xlim=bins[[0,-1]],xlabel='Data value',ylabel='Probability estimate',title=r'$\\bf{B}$)  Histogram (estimated pdf)')\n",
        "\n",
        "  axs[2].plot(binCenters,cdfEst,color=colors[idx],marker=markers[idx],markerfacecolor='w')\n",
        "  axs[2].set(xlim=bins[[0,-1]],xlabel='Data value',ylabel='Cumulative probability',title=r'$\\bf{C}$)  Empirical cdf')\n",
        "\n",
        "\n",
        "axs[1].legend(['Data 1','Data 2','Full data'])\n",
        "axs[2].legend(['Data 1','Data 2','Full data'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('stats_ex2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mHqTV8SC4leG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtvZgvbenqy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 18.3: Triangular pdf from cdf"
      ],
      "metadata": {
        "id": "onjBUmehnqv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 1\n",
        "b = 3\n",
        "d = 4\n",
        "\n",
        "xx = np.linspace(a-1,d+1,901)\n",
        "\n",
        "# piece 1\n",
        "cdf = np.zeros(len(xx))\n",
        "\n",
        "# piece 2\n",
        "whereX = (xx>a) & (xx<=b)\n",
        "cdf[whereX] = (xx[whereX]-a)**2 / ((d-a)*(b-a))\n",
        "\n",
        "# piece 3\n",
        "whereX = (xx>b) & (xx<d)\n",
        "cdf[whereX] = 1 - ( (d-xx[whereX])**2 / ((d-a)*(d-b)) )\n",
        "\n",
        "# piece 4\n",
        "whereX = xx>=d\n",
        "cdf[whereX] = np.ones(np.sum(whereX))\n",
        "\n",
        "# plot the cdf\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(xx,cdf,'k')\n",
        "\n",
        "for p in [a,b,d]:\n",
        "  plt.plot(p,cdf[np.argmin(abs(xx-p))],'ko',markersize=10,markerfacecolor=[.8,.8,.8])\n",
        "\n",
        "plt.gca().set(xlim=xx[[0,-1]],xlabel='$x$',ylabel='Cumulative probability',title='Triangular cdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X7rUGXAfADiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.triang??"
      ],
      "metadata": {
        "id": "MXUbylVywjWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pdf by differentiating the cdf\n",
        "pdf = np.append(0,np.diff(cdf))\n",
        "\n",
        "# pdf via scipy\n",
        "pdfS = stats.triang.pdf(xx,loc=a,c=(b-a)/(d-a),scale=d-a)\n",
        "pdfS *= xx[1]-xx[0] # needs to be scaled by dx\n",
        "\n",
        "\n",
        "# and plot\n",
        "plt.figure(figsize=(9,3.5))\n",
        "plt.plot(xx,pdf,'k',label=r'$p_d(x)$')\n",
        "plt.plot(xx[::20],pdfS[::20],'kd',markerfacecolor=[.5,.5,.5],label=r'$p_s(x)$')\n",
        "plt.plot(a,0,'ks',markersize=12,markerfacecolor='w',label=r'$a=%s$' %a)\n",
        "plt.plot(b,pdf[np.argmin(abs(xx-b))],'ko',markersize=12,markerfacecolor=[.7,.7,.7],label=r'$b=%s$' %b)\n",
        "plt.plot(d,0,'k^',markersize=12,markerfacecolor=[.3,.3,.3],label=r'$d=%s$' %d)\n",
        "\n",
        "plt.legend()\n",
        "plt.gca().set(xlim=xx[[0,-1]],xlabel='x',ylabel='Probability density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('stats_ex3.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F5zOfAcdurpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "od0lGVA5nqse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 18.4: P-value calculations"
      ],
      "metadata": {
        "id": "EynDNPbeszb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zval = 2\n",
        "\n",
        "# 1) from cdf\n",
        "pval = 1 - stats.norm.cdf(zval)\n",
        "\n",
        "# 2) create the pdf\n",
        "N = 1000\n",
        "zz = np.linspace(zval,50,N)\n",
        "dx = zz[1]-zz[0]\n",
        "pdf = stats.norm.pdf(zz)\n",
        "\n",
        "# from pdf using np.sum\n",
        "pFromPdf_np = np.sum(pdf*dx)\n",
        "\n",
        "# 3) from pdf using spi\n",
        "pFromPdf_sp = spi.trapezoid(pdf,dx=dx)\n",
        "\n",
        "# print the results\n",
        "print(f'From cdf     : {pval}')\n",
        "print(f'From np.sum  : {pFromPdf_np}')\n",
        "print(f'From spi.trap: {pFromPdf_sp}')"
      ],
      "metadata": {
        "id": "Hg49aYfMszZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# e.g.,\n",
        "f'{stats.norm.pdf(50):.40f}'"
      ],
      "metadata": {
        "id": "YdlOzCyJszWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QYtzGy7VqtrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 18.5: Empirical vs. analytic moments"
      ],
      "metadata": {
        "id": "8L6_cOctszvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analytic pdf\n",
        "xx = np.linspace(-5,5,555)\n",
        "pdf = stats.norm.pdf(xx)\n",
        "pdf /= np.max(pdf)\n",
        "\n",
        "# empirical pdf estimate from random data\n",
        "sampsize = 5000\n",
        "data = stats.norm.rvs(size=sampsize)\n",
        "heights,bins = np.histogram(data,bins=40)\n",
        "binCenters = (bins[:-1]+bins[1:]) / 2\n",
        "estPdf = heights / np.max(heights)\n",
        "\n",
        "\n",
        "## make the plot\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(xx,pdf,'--',color=[.7,.7,.7],label='Analytic pdf')\n",
        "plt.plot(binCenters,estPdf,'k',label='Empirical pdf')\n",
        "\n",
        "plt.legend()\n",
        "plt.gca().set(xlim=xx[[0,-1]],xlabel='x',ylabel='Probability (norm.)',title=r'$\\bf{A}$)  Normal pdf')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "## calculate moments and print table\n",
        "momentsData = (np.mean(data),np.var(data),stats.skew(data),stats.kurtosis(data))\n",
        "momentsPdf = stats.norm.stats(moments='mvsk')\n",
        "\n",
        "# the js code below increases the font size to make the table match the figure better\n",
        "# https://stackoverflow.com/questions/61957742/how-to-increase-font-size-of-google-colab-cell-output\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''for (rule of document.styleSheets[0].cssRules){if (rule.selectorText=='body') {rule.style.fontSize = '17px'; break}}'''))\n",
        "\n",
        "print(f'Source:    Mean   :    Var.   :    Skew   :  Kurtosis')\n",
        "print(f'-----------------------------------------------------')\n",
        "print(f'  Data:   {momentsData[0]:5.2f}   :   {momentsData[1]:5.2f}   :   {momentsData[2]:5.2f}   :   {momentsData[3]:5.2f}')\n",
        "print(f'  pdf :   {momentsPdf[0]:5.2f}   :   {momentsPdf[1]:5.2f}   :   {momentsPdf[2]:5.2f}   :   {momentsPdf[3]:5.2f}')"
      ],
      "metadata": {
        "id": "o7u7_2JxA_4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analytic pdf\n",
        "xx = np.linspace(.5,5,555)\n",
        "pdf = stats.pareto.pdf(xx,b=5)\n",
        "pdf /= np.max(pdf)\n",
        "\n",
        "# empirical pdf estimate from random data\n",
        "sampsize = 5000\n",
        "data = stats.pareto.rvs(b=5,size=sampsize)\n",
        "heights,bins = np.histogram(data,bins=40)\n",
        "binCenters = (bins[:-1]+bins[1:]) / 2\n",
        "estPdf = heights / np.max(heights)\n",
        "\n",
        "\n",
        "## make the plot\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(xx,pdf,'--',color=[.7,.7,.7],label='Analytic pdf')\n",
        "plt.plot(binCenters,estPdf,'k',label='Empirical pdf')\n",
        "\n",
        "plt.legend()\n",
        "plt.gca().set(xlim=xx[[0,-1]],xlabel='x',ylabel='Probability (norm.)',title=r'$\\bf{B}$)  Pareto pdf')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "## calculate moments and print table\n",
        "momentsData = (np.mean(data),np.var(data),stats.skew(data),stats.kurtosis(data))\n",
        "momentsPdf = stats.pareto.stats(b=5,moments='mvsk')\n",
        "\n",
        "display(Javascript('''for (rule of document.styleSheets[0].cssRules){if (rule.selectorText=='body') {rule.style.fontSize = '17px'; break}}'''))\n",
        "print(f'Source:    Mean   :    Var.   :    Skew   :  Kurtosis')\n",
        "print(f'-----------------------------------------------------')\n",
        "print(f'  Data:   {momentsData[0]:5.2f}   :   {momentsData[1]:5.2f}   :   {momentsData[2]:5.2f}   :   {momentsData[3]:5.2f}')\n",
        "print(f'  pdf :   {momentsPdf[0]:5.2f}   :   {momentsPdf[1]:5.2f}   :   {momentsPdf[2]:5.2f}   :   {momentsPdf[3]:5.2f}')"
      ],
      "metadata": {
        "id": "xdRUqYCZszsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hym0XMbnszpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 18.6: areas"
      ],
      "metadata": {
        "id": "ZxL55HcRszhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# area calculations\n",
        "z1 = 1\n",
        "z2 = 2\n",
        "\n",
        "p_z1z2 = stats.norm.cdf(z2) - stats.norm.cdf(z1)\n",
        "p_z2inf = 1 - stats.norm.cdf(z2)\n",
        "\n",
        "print(f'Area between z = {z1} and z = {z2}: {p_z1z2*100:.2f}%')\n",
        "print(f'Area between z = {z2} and z = oo: {p_z2inf*100:.2f}%')"
      ],
      "metadata": {
        "id": "tm5OVchaszew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the pdf\n",
        "zz = np.linspace(-4,4,305)\n",
        "pdf = stats.norm.pdf(zz) * (zz[1]-zz[0])\n",
        "\n",
        "# draw the figure\n",
        "_,axs = plt.subplots(1,figsize=(10,3.5))\n",
        "\n",
        "axs.plot(zz,pdf,'k',label='pdf')\n",
        "axs.axvline(z1,color='k',linestyle='--',label=fr'$z_1$ = {z1}')\n",
        "axs.axvline(z2,color=[.7,.7,.7],linestyle=':',label=fr'$z_2$ = {z2}')\n",
        "axs.fill_between(zz[(zz>=z1) & (zz<=z2)],pdf[(zz>=z1) & (zz<=z2)],color='k',alpha=.2,label=r'$A([z_1,z_2]) = %.2f \\%% $' %(p_z1z2*100))\n",
        "axs.fill_between(zz[zz>=z2],pdf[zz>=z2],color='k',alpha=.5,label=r'$A([z_2,\\infty)) = %.2f \\%% $' %(p_z2inf*100))\n",
        "axs.legend()\n",
        "axs.set(xlim=zz[[0,-1]],xlabel='z',ylim=[0,1.1*np.max(pdf)],ylabel='Probability density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('stats_ex6.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OflDSX25A3A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTumEbAzA29e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}